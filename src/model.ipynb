{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import zlib\n",
    "import importlib\n",
    "\n",
    "# Third-party imports\n",
    "import cv2\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skimage.transform import resize\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import (KFold, StratifiedKFold, cross_val_score,\n",
    "                                     learning_curve, train_test_split)\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Keras-specific imports\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import (Activation, AveragePooling2D, BatchNormalization,\n",
    "                          Conv2D, Dense, Dropout, Flatten, Lambda, MaxPool2D,\n",
    "                          MaxPooling2D)\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom imports\n",
    "import fit\n",
    "import evaluate\n",
    "import viz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize=50\n",
    "train_dir = \"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/archive/asl_alphabet_train/asl_alphabet_train\"\n",
    "test_dir =  \"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/archive/asl_alphabet_test/asl_alphabet_test\"\n",
    "\n",
    "def get_data(folder):\n",
    "    # Load data and labels from parent folder\n",
    "    X = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        full_path = os.path.join(folder, folderName)  # Create full path to the item\n",
    "        if os.path.isdir(full_path):  # Check if the item is a directory\n",
    "            if not folderName.startswith('.'):\n",
    "                if folderName in ['A']:\n",
    "                    label = 0\n",
    "                elif folderName in ['B']:\n",
    "                    label = 1\n",
    "                elif folderName in ['C']:\n",
    "                    label = 2\n",
    "                elif folderName in ['D']:\n",
    "                    label = 3\n",
    "                elif folderName in ['E']:\n",
    "                    label = 4\n",
    "                elif folderName in ['F']:\n",
    "                    label = 5\n",
    "                elif folderName in ['G']:\n",
    "                    label = 6\n",
    "                elif folderName in ['H']:\n",
    "                    label = 7\n",
    "                elif folderName in ['I']:\n",
    "                    label = 8\n",
    "                elif folderName in ['J']:\n",
    "                    label = 9\n",
    "                elif folderName in ['K']:\n",
    "                    label = 10\n",
    "                elif folderName in ['L']:\n",
    "                    label = 11\n",
    "                elif folderName in ['M']:\n",
    "                    label = 12\n",
    "                elif folderName in ['N']:\n",
    "                    label = 13\n",
    "                elif folderName in ['O']:\n",
    "                    label = 14\n",
    "                elif folderName in ['P']:\n",
    "                    label = 15\n",
    "                elif folderName in ['Q']:\n",
    "                    label = 16\n",
    "                elif folderName in ['R']:\n",
    "                    label = 17\n",
    "                elif folderName in ['S']:\n",
    "                    label = 18\n",
    "                elif folderName in ['T']:\n",
    "                    label = 19\n",
    "                elif folderName in ['U']:\n",
    "                    label = 20\n",
    "                elif folderName in ['V']:\n",
    "                    label = 21\n",
    "                elif folderName in ['W']:\n",
    "                    label = 22\n",
    "                elif folderName in ['X']:\n",
    "                    label = 23\n",
    "                elif folderName in ['Y']:\n",
    "                    label = 24\n",
    "                elif folderName in ['Z']:\n",
    "                    label = 25\n",
    "                elif folderName in ['del']:\n",
    "                    label = 26\n",
    "                elif folderName in ['nothing']:\n",
    "                    label = 27\n",
    "                elif folderName in ['space']:\n",
    "                    label = 28           \n",
    "                else:\n",
    "                    label = 29\n",
    "                for image_filename in tqdm(os.listdir(full_path)):\n",
    "                    img_file = cv2.imread(os.path.join(full_path, image_filename))\n",
    "                    if img_file is not None:\n",
    "                        img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n",
    "                        img_arr = np.asarray(img_file)\n",
    "                        X.append(img_arr)\n",
    "                        y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, Y_train = get_data(train_dir)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, shuffle=True, random_state=23) \n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, random_state=23) \n",
    "\n",
    "\n",
    "Y_trainHot = to_categorical(Y_train, num_classes = 30)\n",
    "\n",
    "# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "y_trainHot = to_categorical(y_train, num_classes = 30)\n",
    "y_testHot = to_categorical(y_test, num_classes = 30)\n",
    "y_valHot = to_categorical(y_val, num_classes = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle since data was loaded in order of class\n",
    "\n",
    "X_train, y_trainHot = shuffle(X_train, y_trainHot, random_state=13)\n",
    "X_test, y_testHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "X_val, y_valHot = shuffle(X_test, y_testHot, random_state=13)\n",
    "\n",
    "# X_train = X_train[:30000]\n",
    "# X_test = X_test[:30000]\n",
    "# y_trainHot = y_trainHot[:30000]\n",
    "# y_testHot = y_testHot[:30000]\n",
    "\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"delete\", \"nothing\", \"space\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_train.npy', X_train)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_test.npy', X_test)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_trainHot.npy', y_trainHot)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_testHot.npy', y_testHot)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_train.npy', y_train)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_test.npy', y_test)\n",
    "\n",
    "\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_val.npy', X_val)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_val.npy', y_val)\n",
    "np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_valHot.npy', y_valHot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.distPlot(y_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "X_val_scaled = scaler.transform(X_val.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply PCA\n",
    "# pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "# X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "# X_val_pca = pca.transform(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_train_pca.npy', X_train_pca)\n",
    "# np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_test_pca.npy', X_test_pca)\n",
    "# np.save('/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_val_pca.npy', X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explained variance plot\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Cumulative explained variance')\n",
    "# plt.title('Explained variance by different principal components')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_test_pca.npy\")\n",
    "y_test = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_test.npy\")\n",
    "y_testHot = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_testHot.npy\")\n",
    "X_test = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_test.npy\")\n",
    "X_val = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_val.npy\")\n",
    "y_val = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_val.npy\")\n",
    "X_train = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/X_train.npy\")\n",
    "y_train = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_train.npy\")\n",
    "y_trainHot = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_trainHot.npy\")\n",
    "y_valHot = np.load(\"/Users/mnorton/Desktop/College/Grad Victory Lap/CMSE 890/data/y_valHot.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space'}\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {classes[i]: class_weights[i] for i in range(len(classes))}\n",
    "\n",
    "weight_path = 'keras_pre-trained_models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# weight_path2 = 'keras_pre-trained_models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pretrained = VGG16(weights = weight_path, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "# pretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = keras.optimizers.Adam()\n",
    "# optimizer2 = keras.optimizers.RMSprop(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history1, model1 = fit.scaled1dNetwork(X_train_pca, y_trainHot, X_val_pca, y_valHot,class_weight_dict,30,20,optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 286ms/step - accuracy: 0.4887 - loss: 2.2517 - val_accuracy: 0.7828 - val_loss: 1.0910\n",
      "Epoch 2/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 256ms/step - accuracy: 0.8051 - loss: 0.9742 - val_accuracy: 0.8474 - val_loss: 0.7439\n",
      "Epoch 3/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 249ms/step - accuracy: 0.8643 - loss: 0.6841 - val_accuracy: 0.8806 - val_loss: 0.5793\n",
      "Epoch 4/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 251ms/step - accuracy: 0.8934 - loss: 0.5393 - val_accuracy: 0.9045 - val_loss: 0.4753\n",
      "Epoch 5/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 263ms/step - accuracy: 0.9132 - loss: 0.4450 - val_accuracy: 0.9185 - val_loss: 0.4052\n",
      "Epoch 6/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 258ms/step - accuracy: 0.9261 - loss: 0.3793 - val_accuracy: 0.9277 - val_loss: 0.3574\n",
      "Epoch 7/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 247ms/step - accuracy: 0.9360 - loss: 0.3306 - val_accuracy: 0.9361 - val_loss: 0.3174\n",
      "Epoch 8/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 266ms/step - accuracy: 0.9405 - loss: 0.2986 - val_accuracy: 0.9415 - val_loss: 0.2878\n",
      "Epoch 9/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 288ms/step - accuracy: 0.9487 - loss: 0.2691 - val_accuracy: 0.9462 - val_loss: 0.2629\n",
      "Epoch 10/10\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 263ms/step - accuracy: 0.9533 - loss: 0.2450 - val_accuracy: 0.9521 - val_loss: 0.2417\n"
     ]
    }
   ],
   "source": [
    "history, model = fit.pretrainedNetwork(X_train, y_trainHot, X_val, y_valHot,pretrained,weight_path,class_weight_dict,30,10,optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.save('assets/models/ASL_DNN_1D.keras')\n",
    "# model1.save(\"assets/models/ASL_DNN_1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('assets/models/ASL_DNN_3D.keras')\n",
    "model.save(\"assets/models/ASL_DNN_3D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.predict(np.expand_dims(X_val_pca[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Predict the classes for the 1D test set\n",
    "# y_pred1DHot = model1.predict(X_test_pca)\n",
    "\n",
    "# # If the predictions are probabilities (as with some models), \n",
    "# # you'll need to convert to predicted class labels by taking the argmax\n",
    "# if y_pred1DHot.ndim > 1:\n",
    "#     y_pred1D = np.argmax(y_pred1DHot, axis=1)\n",
    "\n",
    "# # Ensure 'y_test' is not one-hot encoded. If it is, convert it:\n",
    "# if y_testHot.ndim > 1:\n",
    "#     y_test1D = np.argmax(y_testHot, axis=1)\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# accuracy = accuracy_score(y_test1D, y_pred1D)\n",
    "\n",
    "# print(f\"Accuracy score: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print('\\n', classification_report(np.where(y_testHot > 0)[1], np.argmax(model1.predict(X_test_pca), axis=1), target_names=labels), sep='') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_confusion_matrix(y_true, y_pred, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "#     # Compute confusion matrix\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     print(cm)\n",
    "\n",
    "#     # Export to CSV\n",
    "#     np.savetxt('confusion_matrix.csv', cm, delimiter=',', fmt='%d')\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "#     im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     # ax.figure.colorbar(im, ax=ax)\n",
    "#     # Show all ticks and label them with the respective list entries\n",
    "#     ax.set(xticks=np.arange(cm.shape[1]),\n",
    "#            yticks=np.arange(cm.shape[0]),\n",
    "#            xticklabels=classes, yticklabels=classes,\n",
    "#            title=title,\n",
    "#            ylabel='True label',\n",
    "#            xlabel='Predicted label')\n",
    "    \n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#              rotation_mode=\"anchor\")\n",
    "    \n",
    "#     # Loop over data dimensions and create text annotations.\n",
    "#     fmt = 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             ax.text(j, i, format(cm[i, j], fmt),\n",
    "#                     ha=\"center\", va=\"center\",\n",
    "#                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#     fig.tight_layout()\n",
    "#     return ax\n",
    "\n",
    "# # Predict classes on the test set\n",
    "# y_pred_prob = model1.predict(X_test_pca)\n",
    "# y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# y_true = np.argmax(y_testHot, axis=1)  # Assuming ytest is one-hot encoded\n",
    "\n",
    "# # Assuming you have a list of class names as 'class_names'\n",
    "# plot_confusion_matrix(y_true, y_pred, classes=labels)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 160ms/step\n",
      "Accuracy score: 0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Predict the classes for the 3D test set\n",
    "y_pred3D = model.predict(X_test)\n",
    "\n",
    "# If the predictions are probabilities (as with some models), \n",
    "# you'll need to convert to predicted class labels by taking the argmax\n",
    "if y_pred3D.ndim > 1:\n",
    "    y_pred3D = np.argmax(y_pred3D, axis=1)\n",
    "\n",
    "# Ensure 'y_test' is not one-hot encoded. If it is, convert it:\n",
    "if y_test.ndim > 1:\n",
    "    y_test3D = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred3D)\n",
    "\n",
    "print(f\"Accuracy score: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred3D)\n",
    "\n",
    "print(f\"Accuracy score: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate.evaluate(model1, history1, X_test, y_testHot, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
